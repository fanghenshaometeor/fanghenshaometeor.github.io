---
permalink: /
title: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a Ph.D. student in [Institute of Image Processing and Pattern Recognition](http://www.pami.sjtu.edu.cn/) of [Department of Automation](https://automation.sjtu.edu.cn/) at [Shanghai Jiao Tong University](https://www.sjtu.edu.cn/). My advisor is [Prof. Jie YANG](https://scholar.google.com/citations?user=tmx7tu8AAAAJ&hl=en).

Before coming to SJTU, I received the BA.Eng. degree in [College of Electronic and Information Engineering](https://see.tongji.edu.cn/) from [Tongji University](https://www.tongji.edu.cn/) in 2018. I then received the MA.Eng. degree in [Department of Automation](https://automation.sjtu.edu.cn/) from [Shanghai Jiao Tong University](https://www.sjtu.edu.cn/) in 2021.


Research interests
---
My research interests focus on **trustworthy deep learning**. Currently, my works are about the **robustness** of Deep Neural Networks (DNNs) against those *pixel-perturbed* or *distribution-shifted* inputs, within the fields of **adversarial learning** and **out-of-distribution detection**.

- DNNs trained on clean images show terrible generalization performance on those carefully-designed invisible perturbed images, *i.e.*, *adversarial examples*, which has raised widespread attention on the *adversarial robustness* of DNNs.
- DNNs cannot generalize well on data that differs from the training distribution, *i.e.*, *In-Distribution (InD)*. In this regard, it remains a valuable task of detecting whether new samples are from the InD or OoD (Out-of-Distribution) of DNNs in the inference stage.

In addition, I have previously dabbled in the **random Fourier features**, a sub-field of the **kernel methods** in machine learning.

---


Awards
---
- Outstanding Reviewer for [ECCV 2024](http://fanghenshaometeor.github.io/files/outstandingreviewereccv2024.pdf).